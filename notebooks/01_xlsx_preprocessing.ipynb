{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preprocessing the XLSX Data\n",
    "\n",
    "## TODO: Add Stations related info to the measurement files, preprocess the data for NN and Time Series models (you can safely start from air_quality_2019_2023.csv)\n",
    "\n",
    "## Imports"
   ],
   "id": "35f959061be3307e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:53:59.672811Z",
     "start_time": "2025-09-16T13:53:59.390653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ],
   "id": "1b101dc5ef95b3e0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stations\n",
    "- renaming columns"
   ],
   "id": "e4e447a94224108f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T12:09:15.952973Z",
     "start_time": "2025-09-15T12:09:15.937006Z"
    }
   },
   "source": [
    "# Read the Excel file (specific sheet)\n",
    "df = pd.read_excel(\"../data/raw/Stations.xlsx\")\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"Station Code\" : \"station_code\",\n",
    "    \"International Code\": \"int_code\",\n",
    "    \"Street address\": \"address\",\n",
    "    \"Area Type\": \"area_type\",\n",
    "    \"Station Category\": \"station_category\",\n",
    "    \"WGS84 φ N\": \"latitude\",\n",
    "    \"WGS84 λ E\": \"longitude\"\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"../data/processed/stations.csv\", index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   station_code int_code                     address area_type  \\\n",
      "0  MpKrakAlKras  PL0012A  Kraków, Aleja Krasińskiego     urban   \n",
      "1  MpKrakBujaka  PL0501A          Kraków, ul. Bujaka     urban   \n",
      "2  MpKrakBulwar  PL0039A       Kraków, ul. Bulwarowa     urban   \n",
      "3  MpKrakOsPias  PL0642A         Kraków, os. Piastów     urban   \n",
      "4  MpKrakSwoszo  PL0735A      Kraków, os. Swoszowice     urban   \n",
      "\n",
      "             station_category   latitude  longitude  \n",
      "0   stationary container unit  50.057678  19.926189  \n",
      "1   stationary container unit  50.010575  19.949189  \n",
      "2   stationary container unit  50.069308  20.053492  \n",
      "3  free-standing dust sampler  50.098508  20.018269  \n",
      "4  free-standing dust sampler  49.991442  19.936792  \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Measurements Merge\n",
    "- merging measurements from 2019 to 2023\n",
    "- cleaning datetime (2020 had another format of time (07:59:59.712000)"
   ],
   "id": "7f9cd097dbed9752"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T12:29:30.045303Z",
     "start_time": "2025-09-15T12:29:26.625378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = Path(\"../data/raw/AirQuality_Krakow\")\n",
    "files = sorted(data_dir.glob(\"*.xlsx\"))\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    print(f\"\\n=== Processing file: {f.name} ===\")\n",
    "    df = pd.read_excel(f, dtype=str)\n",
    "\n",
    "    # keep raw for cleaning only\n",
    "    df[\"DateTime_clean\"] = df[\"DateTime\"].str.split(\".\").str[0]\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime_clean\"], errors=\"coerce\")\n",
    "\n",
    "    # sanity check\n",
    "    if df[\"DateTime\"].isna().any():\n",
    "        print(f\"⚠️ Found {df['DateTime'].isna().sum()} bad rows in {f.name}\")\n",
    "    else:\n",
    "        print(\"✅ All DateTime parsed correctly.\")\n",
    "\n",
    "    # drop helpers\n",
    "    df = df.drop(columns=[\"DateTime_clean\"])\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge into one DataFrame\n",
    "data = pd.concat(dfs, ignore_index=True).sort_values(\"DateTime\")\n",
    "\n",
    "print(\"\\nFinal merged shape:\", data.shape)\n",
    "print(data.head())\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv(\"../data/processed/air_quality_2019_2023.csv\", index=False)\n",
    "print(\"✅ Saved clean dataset to ../data/processed/air_quality_2019_2023.csv\")"
   ],
   "id": "cfc49a1af425287d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing file: 2019_PM10_1g.xlsx ===\n",
      "✅ All DateTime parsed correctly.\n",
      "\n",
      "=== Processing file: 2020_PM10_1g.xlsx ===\n",
      "✅ All DateTime parsed correctly.\n",
      "\n",
      "=== Processing file: 2021_PM10_1g.xlsx ===\n",
      "✅ All DateTime parsed correctly.\n",
      "\n",
      "=== Processing file: 2022_PM10_1g.xlsx ===\n",
      "✅ All DateTime parsed correctly.\n",
      "\n",
      "=== Processing file: 2023_PM10_1g.xlsx ===\n",
      "✅ All DateTime parsed correctly.\n",
      "\n",
      "Final merged shape: (43824, 8)\n",
      "             DateTime MpKrakAlKras MpKrakBujaka MpKrakBulwar MpKrakOsPias  \\\n",
      "0 2019-01-01 01:00:00      88.2185       139.79      120.057      161.053   \n",
      "1 2019-01-01 02:00:00      95.2209      92.5099      63.4217      62.3289   \n",
      "2 2019-01-01 03:00:00      85.3689      57.1358      48.6426      56.5202   \n",
      "3 2019-01-01 04:00:00      70.8575      39.4615      36.7828      49.5539   \n",
      "4 2019-01-01 05:00:00      50.1935      27.1423      28.7538      36.1824   \n",
      "\n",
      "  MpKrakSwoszo MpKrakWadow MpKrakZloRog  \n",
      "0          NaN     83.6841      77.8355  \n",
      "1          NaN     66.3402      82.9678  \n",
      "2          NaN     55.8833      64.5276  \n",
      "3          NaN     44.1614      46.5672  \n",
      "4          NaN     34.5853      48.1257  \n",
      "✅ Saved clean dataset to ../data/processed/air_quality_2019_2023.csv\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Date Features Engineering for Tree-Based Models\n",
    "- extracting date related features for tree-based models\n",
    "- cyclic encoding of hour of the day, day of year and weekday\n",
    "- dropping of the original dateTime column"
   ],
   "id": "7c4cdb1d5d71f6b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T12:38:43.448979Z",
     "start_time": "2025-09-15T12:38:42.852188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your merged CSV\n",
    "data = pd.read_csv(\"../data/processed/air_quality_2019_2023.csv\", parse_dates=[\"DateTime\"])\n",
    "\n",
    "# Extract basic time features\n",
    "data[\"year\"] = data[\"DateTime\"].dt.year\n",
    "data[\"month\"] = data[\"DateTime\"].dt.month\n",
    "data[\"day\"] = data[\"DateTime\"].dt.day\n",
    "data[\"weekday\"] = data[\"DateTime\"].dt.weekday  # Monday=0\n",
    "data[\"hour\"] = data[\"DateTime\"].dt.hour\n",
    "data[\"day_of_year\"] = data[\"DateTime\"].dt.dayofyear\n",
    "\n",
    "# Cyclic encoding for hour (24h cycle)\n",
    "data[\"hour_sin\"] = np.sin(2 * np.pi * data[\"hour\"] / 24)\n",
    "data[\"hour_cos\"] = np.cos(2 * np.pi * data[\"hour\"] / 24)\n",
    "\n",
    "# Cyclic encoding for day of year (seasonality)\n",
    "data[\"doy_sin\"] = np.sin(2 * np.pi * data[\"day_of_year\"] / 365.25)\n",
    "data[\"doy_cos\"] = np.cos(2 * np.pi * data[\"day_of_year\"] / 365.25)\n",
    "\n",
    "# Optional: encode weekday cyclically\n",
    "data[\"weekday_sin\"] = np.sin(2 * np.pi * data[\"weekday\"] / 7)\n",
    "data[\"weekday_cos\"] = np.cos(2 * np.pi * data[\"weekday\"] / 7)\n",
    "\n",
    "# Drop the original DateTime if you want only numeric features for trees\n",
    "data = data.drop(columns=[\"DateTime\"])\n",
    "\n",
    "# Save the dataset ready for tree-based ML\n",
    "data.to_csv(\"../data/processed/air_quality_2019_2023_tree_features.csv\", index=False)\n",
    "print(\"✅ Saved dataset with tree-based features\")\n",
    "print(data.head())"
   ],
   "id": "37de25b7cc784b8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved dataset with tree-based features\n",
      "   MpKrakAlKras  MpKrakBujaka  MpKrakBulwar  MpKrakOsPias  MpKrakSwoszo  \\\n",
      "0       88.2185      139.7900      120.0570      161.0530           NaN   \n",
      "1       95.2209       92.5099       63.4217       62.3289           NaN   \n",
      "2       85.3689       57.1358       48.6426       56.5202           NaN   \n",
      "3       70.8575       39.4615       36.7828       49.5539           NaN   \n",
      "4       50.1935       27.1423       28.7538       36.1824           NaN   \n",
      "\n",
      "   MpKrakWadow  MpKrakZloRog  year  month  day  weekday  hour  day_of_year  \\\n",
      "0      83.6841       77.8355  2019      1    1        1     1            1   \n",
      "1      66.3402       82.9678  2019      1    1        1     2            1   \n",
      "2      55.8833       64.5276  2019      1    1        1     3            1   \n",
      "3      44.1614       46.5672  2019      1    1        1     4            1   \n",
      "4      34.5853       48.1257  2019      1    1        1     5            1   \n",
      "\n",
      "   hour_sin  hour_cos   doy_sin   doy_cos  weekday_sin  weekday_cos  \n",
      "0  0.258819  0.965926  0.017202  0.999852     0.781831      0.62349  \n",
      "1  0.500000  0.866025  0.017202  0.999852     0.781831      0.62349  \n",
      "2  0.707107  0.707107  0.017202  0.999852     0.781831      0.62349  \n",
      "3  0.866025  0.500000  0.017202  0.999852     0.781831      0.62349  \n",
      "4  0.965926  0.258819  0.017202  0.999852     0.781831      0.62349  \n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Melting the data - 1 row per measurement per station\n",
    "- breaking the original file from wide (1 row per timestamp) to long (1 row per timestamp per station)\n",
    "- dropping of N/A rows for training purposes"
   ],
   "id": "aab7ed5cb2739edc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T16:20:56.572731Z",
     "start_time": "2025-09-19T16:20:54.085701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned dataset with tree features\n",
    "data = pd.read_csv(\"../data/processed/air_quality_2019_2023_tree_features.csv\")\n",
    "\n",
    "# Identify the station columns\n",
    "station_cols = [\n",
    "    \"MpKrakAlKras\", \"MpKrakBujaka\", \"MpKrakBulwar\", \n",
    "    \"MpKrakOsPias\", \"MpKrakSwoszo\", \"MpKrakWadow\", \"MpKrakZloRog\"\n",
    "]\n",
    "\n",
    "# Melt to long format\n",
    "data_long = data.melt(\n",
    "    id_vars=[\n",
    "        \"year\", \"month\", \"day\", \"weekday\", \"hour\", \"day_of_year\",\n",
    "        \"hour_sin\", \"hour_cos\", \"doy_sin\", \"doy_cos\", \"weekday_sin\", \"weekday_cos\"\n",
    "    ],\n",
    "    value_vars=station_cols,\n",
    "    var_name=\"station_code\",\n",
    "    value_name=\"pm10\"\n",
    ")\n",
    "\n",
    "# Sort by station and datetime for proper lag computation\n",
    "data_long = data_long.sort_values([\"station_code\", \"year\", \"month\", \"day\", \"hour\"])\n",
    "\n",
    "# Compute lag features per station\n",
    "lag_hours = [1, 2]  # lag 1 hour, 2 hours\n",
    "for lag in lag_hours:\n",
    "    data_long[f\"pm10_lag_{lag}\"] = data_long.groupby(\"station_code\")[\"pm10\"].shift(lag)\n",
    "\n",
    "# Drop rows where pm10 is missing\n",
    "data_long = data_long.dropna(subset=[\"pm10\"])\n",
    "\n",
    "# Optional: reset index\n",
    "data_long = data_long.reset_index(drop=True)\n",
    "\n",
    "print(\"Long format shape:\", data_long.shape)\n",
    "print(data_long.head())\n",
    "\n",
    "# Save the long format dataset ready for general model\n",
    "data_long.to_csv(\"../data/processed/air_quality_2019_2023_long.csv\", index=False)\n",
    "print(\"✅ Saved long-format dataset with PM10 lag features.\")"
   ],
   "id": "bab33cb31cfe5d51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long format shape: (290736, 16)\n",
      "   year  month  day  weekday  hour  day_of_year  hour_sin  hour_cos   doy_sin  \\\n",
      "0  2019      1    1        1     1            1  0.258819  0.965926  0.017202   \n",
      "1  2019      1    1        1     2            1  0.500000  0.866025  0.017202   \n",
      "2  2019      1    1        1     3            1  0.707107  0.707107  0.017202   \n",
      "3  2019      1    1        1     4            1  0.866025  0.500000  0.017202   \n",
      "4  2019      1    1        1     5            1  0.965926  0.258819  0.017202   \n",
      "\n",
      "    doy_cos  weekday_sin  weekday_cos  station_code     pm10  pm10_lag_1  \\\n",
      "0  0.999852     0.781831      0.62349  MpKrakAlKras  88.2185         NaN   \n",
      "1  0.999852     0.781831      0.62349  MpKrakAlKras  95.2209     88.2185   \n",
      "2  0.999852     0.781831      0.62349  MpKrakAlKras  85.3689     95.2209   \n",
      "3  0.999852     0.781831      0.62349  MpKrakAlKras  70.8575     85.3689   \n",
      "4  0.999852     0.781831      0.62349  MpKrakAlKras  50.1935     70.8575   \n",
      "\n",
      "   pm10_lag_2  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2     88.2185  \n",
      "3     95.2209  \n",
      "4     85.3689  \n",
      "✅ Saved long-format dataset with PM10 lag features.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T13:00:33.013835Z",
     "start_time": "2025-09-15T13:00:33.010858Z"
    }
   },
   "cell_type": "code",
   "source": "print(data_long.shape)",
   "id": "41f28bcb3231240d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290736, 14)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T13:54:02.177492Z",
     "start_time": "2025-09-16T13:54:02.087813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_tree = pd.read_csv(\"../data/processed/air_quality_2019_2023_tree_features.csv\")\n",
    "print(data_tree.shape)"
   ],
   "id": "79e22884f4aa915",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43824, 19)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "aa3a86b82b5a9040"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
